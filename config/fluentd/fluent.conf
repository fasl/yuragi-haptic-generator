# Fluentd configuration for Yuragi Haptic Generator
# Handles log collection, parsing, and routing

# Input sources
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Backend service logs
<filter backend.**>
  @type parser
  key_name log
  reserve_data true
  reserve_time true
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%LZ
  </parse>
</filter>

# Frontend service logs (Nginx access logs)
<filter frontend.**>
  @type parser
  key_name log
  reserve_data true
  reserve_time true
  <parse>
    @type nginx
    expression /^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?/
    time_format %d/%b/%Y:%H:%M:%S %z
  </parse>
</filter>

# Add metadata to all logs
<filter **>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    service_name ${tag_parts[0]}
    container_name ${tag_parts[1]}
    environment ${ENV['ENVIRONMENT'] || 'production'}
    project yuragi-haptic-generator
  </record>
</filter>

# Error log enrichment
<filter **>
  @type grep
  <regexp>
    key level
    pattern ^(ERROR|CRITICAL|error)$
  </regexp>
  <record>
    alert_level high
    needs_attention true
  </record>
</filter>

# Route logs based on level and service
<match backend.**>
  @type copy
  
  # Store all backend logs to file
  <store>
    @type file
    path /var/log/containers/backend
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    buffer_type file
    buffer_path /var/log/containers/backend.*.buffer
    flush_interval 10s
    <format>
      @type json
    </format>
  </store>
  
  # Send errors to separate error log
  <store>
    @type grep
    <regexp>
      key level
      pattern ^(ERROR|CRITICAL)$
    </regexp>
    @type file
    path /var/log/containers/backend_errors
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    <format>
      @type json
    </format>
  </store>
  
  # Send to Elasticsearch if available
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name yuragi-backend-logs
    type_name _doc
    time_key @timestamp
    time_key_format %Y-%m-%dT%H:%M:%S.%NZ
    include_timestamp true
    reconnect_on_error true
    reload_on_failure true
    reload_connections false
    <buffer>
      @type file
      path /var/log/containers/backend_es.*.buffer
      flush_mode interval
      retry_type exponential_backoff
      flush_thread_count 2
      flush_interval 5s
      retry_forever
      retry_max_interval 30
      chunk_limit_size 2M
      queue_limit_length 8
      overflow_action block
    </buffer>
  </store>
</match>

<match frontend.**>
  @type copy
  
  # Store all frontend logs to file
  <store>
    @type file
    path /var/log/containers/frontend
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    buffer_type file
    buffer_path /var/log/containers/frontend.*.buffer
    flush_interval 10s
    <format>
      @type json
    </format>
  </store>
  
  # Send errors (4xx, 5xx) to separate error log
  <store>
    @type grep
    <regexp>
      key code
      pattern ^[45]\d\d$
    </regexp>
    @type file
    path /var/log/containers/frontend_errors
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    <format>
      @type json
    </format>
  </store>
  
  # Send to Elasticsearch if available
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name yuragi-frontend-logs
    type_name _doc
    time_key @timestamp
    time_key_format %Y-%m-%dT%H:%M:%S.%NZ
    include_timestamp true
    reconnect_on_error true
    reload_on_failure true
    reload_connections false
    <buffer>
      @type file
      path /var/log/containers/frontend_es.*.buffer
      flush_mode interval
      retry_type exponential_backoff
      flush_thread_count 2
      flush_interval 5s
      retry_forever
      retry_max_interval 30
      chunk_limit_size 2M
      queue_limit_length 8
      overflow_action block
    </buffer>
  </store>
</match>

# Catch-all for any unmatched logs
<match **>
  @type file
  path /var/log/containers/unknown
  append true
  time_slice_format %Y%m%d
  time_slice_wait 10m
  time_format %Y-%m-%dT%H:%M:%S.%NZ
  <format>
    @type json
  </format>
</match>

# System metrics (optional)
<source>
  @type systemd
  matches [{ "_SYSTEMD_UNIT": "docker.service" }]
  read_from_head true
  tag systemd.docker
</source>

# Monitor Fluentd itself
<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>